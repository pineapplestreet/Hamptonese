#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Mon Nov  1 11:58:37 2021@author: joshpause"""# libraries usedimport reimport pandas as pd# start with original transcription by Stamp & Le (mostly Le)# http://www.cs.sjsu.edu/faculty/stamp/Hampton/hampton.htmlmy_file = open("HampTrans.txt", "r")content_list = my_file.readlines()# we need to make a lot of assumptions here# assuming Stamp & Le are right and we read this left-to-right, top-to-bottom# pages 88 and 96 contain 2 "REVELATIONS", otherwise one per page# forgive some ugly code, but it gets 'er doneclean_data = pd.DataFrame()revelation = 0for row in content_list:        # deal with a new page    if '<<' in row:                # reset line number        line_no = 0                # each new page is a new revelation        revelation += 1                        # get the "official" page number        x = re.search('<<p([0-9]{2,}) ', row)        if x:            page_no = x.group(1)                    # get the page number used by Hampton        x = re.search('\((.*)\)', row)        if x:            hampton_page_no = x.group(1)                    # used for cleanup        x = re.search('<<(.*)>>', row)        if x:            page_no_special = x.group(1)                    # mark as duplicate content        if 'duplicate' in row:            duplicate = 'Y'        else:            duplicate = 'N'                                            # in cases where Hampton put multiple page numbers, assuming the one on the right is the "real" one        if hampton_page_no == '2 and 16':            hampton_page_no = 2        elif hampton_page_no == '15, 3':            hampton_page_no = 3          elif hampton_page_no == '60) duplicate of 126 (60':            hampton_page_no = 60        elif page_no_special == 'p131 duplicate of 129':            hampton_page_no = 61        elif page_no_special == 'p132 duplicate of 130':            hampton_page_no = 62                                        # not a new page    else:              # set indexes        line_no += 1           char_no = 0          if duplicate=='Y':            print(duplicate)            print(row)                                    # special rule for English         row = row.replace("[St James]","[St_James]")               # split char and make one row per                chars = row.split()                                # cycle through all characters                     for char in chars:            char_no += 1            if char=='[REVELATION]':                revelation += 1             else:                                # create dataframe row for each character                row = pd.DataFrame({'page_no':[int(page_no)],                                    'hampton_page_no':[int(hampton_page_no)],                                    'duplicate_content':[duplicate],                                    'line_no':[int(line_no)],                                    'char_no':[int(char_no)],                                    'revelation':[int(revelation)],                                    'char':[char]})                 clean_data = clean_data.append(row)                          # save as a CSV for easy sharingclean_data.to_csv("HampTrans.csv",index=False)                